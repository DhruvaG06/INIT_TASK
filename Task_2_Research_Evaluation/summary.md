**Title:** ImageNet Classification with Deep Convolutional Neural Networks

**Authors:** Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton 
**Publication:** Communications of the ACM, Vol. 60, No. 6 (2017)  
**DOI:** [https://doi.org/10.1145/3065386]

**Task 1(Paper Review):**
The 2012 paper "ImageNet Classification with Deep Convolutional Neural Networks" by Krizhevsky, Sutskever, and Hinton introduced the deep CNN AlexNet, one that proved revolutionary in image recognition. The basic idea was to classify 1.2 million high-resolution images from the ImageNet dataset into 1,000 categories using an eight-layer large neural network, comprising five convolutional and three fully connected layers. This model was devised with many state-of-the-art techniques aimed at improving efficiency, including ReLU activation, GPU parallelization, local response normalization, overlapping pooling, data augmentation, and dropout to avoid overfitting. Trained for almost six days on two GPUs, AlexNet achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, far superior to all the earlier methods. This single architecture succeeded in causing a paradigm shift in computer vision and popularizing deep learning as the dominant method for image classification tasks.

**Task 2(Reflection):**
This paper is a significant step in artificial intelligence. It marks the shift when deep learning moved from theory to real-world use. Its strength comes from combining smart engineering, such as using GPUs and dropout, with a clear understanding of the limitations of neural networks at that time. However, a major drawback is its dependence on large labelled datasets and computational resources. Training took several days on powerful GPUs and required millions of annotated images, making it hard for smaller research groups to access. Even though the model achieved impressive accuracy, it was not easy to understand. It lacked explainability. It offered little insight into why it made certain predictions.
A promising direction could be multi-modal learning, where image data is combined with text or contextual information, allowing models to reason more like humans. By moving toward such architectures, future systems can build on AlexNet’s foundation while becoming more efficient, explainable, and generalizable beyond single-image classification tasks. Future directions could also explore model compression and energy-efficient architectures to make deep learning more sustainable and accessible.

**Task 3(Implementation Idea):**
The AlexNet architecture proved that deep convolutional neural networks could achieve extraordinary accuracy in image recognition — but at the cost of enormous computational power, memory, and energy consumption. This project, EcoNet, reimagines AlexNet’s principles for today’s world by designing a lightweight, energy-efficient CNN that delivers strong performance with far fewer parameters.
EcoNet involves building and comparing two models: a simplified AlexNet-style network and a compressed variant that applies pruning, quantization, and depthwise separable convolutions to minimize computation. Both models are trained on an accessible dataset such as CIFAR-10 or FashionMNIST. Their performance is evaluated based on accuracy, model size, and inference speed.
Preliminary experiments show that EcoNet can retain over 90% of baseline accuracy while reducing computation by nearly half, highlighting the potential for sustainable AI. The project demonstrates that deep learning’s future lies not only in larger models but in smarter, greener architectures — maintaining AlexNet’s legacy while addressing its biggest limitation: efficiency.

